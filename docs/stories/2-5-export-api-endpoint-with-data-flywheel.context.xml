<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>5</storyId>
    <title>Export API Endpoint with Data Flywheel</title>
    <status>ready-for-dev</status>
    <generatedAt>2025-11-08</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/2-5-export-api-endpoint-with-data-flywheel.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>a system</asA>
    <iWant>to capture both original and edited transcriptions during export</iWant>
    <soThat>I can build training data for future model improvements</soThat>
    <tasks>- [ ] Task 1: Create export service module with SRT and TXT generation (AC: #2, #3)
  - [ ] Create `backend/app/services/export_service.py` file
  - [ ] Implement `generate_srt(segments: List[TranscriptionSegment]) -> str` function
  - [ ] SRT format: `1\n00:00:00,500 --> 00:00:03,200\nSubtitle text\n\n`
  - [ ] Handle timestamp conversion: float seconds → HH:MM:SS,mmm format
  - [ ] Implement `generate_txt(segments: List[TranscriptionSegment]) -> str` function
  - [ ] TXT format: Space-separated text only, no timestamps
  - [ ] Test: Generate SRT from 3-segment sample, verify format correct
  - [ ] Test: Generate TXT from 3-segment sample, verify plain text output

- [ ] Task 2: Create Pydantic models for export API (AC: #1)
  - [ ] Add `ExportRequest` model to `backend/app/models.py`
  - [ ] Fields: `segments: list[TranscriptionSegment]`, `format: Literal['srt', 'txt']`
  - [ ] Add `ExportMetadata` model for data flywheel storage
  - [ ] Fields: `job_id`, `original_segment_count`, `edited_segment_count`, `export_timestamp`, `format_requested`, `changes_detected`
  - [ ] Test: Validate ExportRequest with valid/invalid format values
  - [ ] Test: Validate segments array must not be empty

- [ ] Task 3: Implement data flywheel storage logic (AC: #4, #5)
  - [ ] Create `save_edited_transcription(job_id, segments, format)` function in export_service.py
  - [ ] Load original transcription from `/uploads/{job_id}/transcription.json`
  - [ ] Compare original vs edited segments: count `changes_detected` (text differences)
  - [ ] Save edited version to `/uploads/{job_id}/edited.json` with segments + metadata
  - [ ] Save export metadata to `/uploads/{job_id}/export_metadata.json`
  - [ ] Metadata JSON structure: `{"job_id": "...", "original_segment_count": 45, "edited_segment_count": 45, "export_timestamp": "2025-11-07T...", "format_requested": "srt", "changes_detected": 7}`
  - [ ] Test: Export with edits, verify edited.json created with correct structure
  - [ ] Test: Verify changes_detected counts text differences accurately
  - [ ] Test: Export with no edits, verify changes_detected = 0

- [ ] Task 4: Implement POST /export/{job_id} endpoint (AC: #1, #6, #7)
  - [ ] Add endpoint to `backend/app/main.py`
  - [ ] Route: `@app.post("/export/{job_id}")`
  - [ ] Request body: `ExportRequest` (segments array + format)
  - [ ] Validate job_id exists (check `/uploads/{job_id}/transcription.json`)
  - [ ] Call export_service.generate_srt() or generate_txt() based on format
  - [ ] Call export_service.save_edited_transcription() for data flywheel
  - [ ] Return `Response` with file content, correct Content-Type, Content-Disposition header
  - [ ] Content-Type: `application/x-subrip` (SRT) or `text/plain` (TXT)
  - [ ] Content-Disposition: `attachment; filename=transcript-{job_id}.{ext}`
  - [ ] Error handling: 404 if job not found, 400 if invalid format or empty segments
  - [ ] Test: POST with SRT format, verify file download response
  - [ ] Test: POST with TXT format, verify file download response
  - [ ] Test: POST with non-existent job_id, verify 404 error
  - [ ] Test: POST with invalid format, verify 400 error

- [ ] Task 5: Add logging for data flywheel and export operations (AC: #4, #5)
  - [ ] Log export requests: `logger.info(f"Export requested: job={job_id}, format={format}, segments={len(segments)}")`
  - [ ] Log data flywheel captures: `logger.info(f"Data flywheel: Detected {changes_count} edited segments for job {job_id}")`
  - [ ] Log export generation duration: `logger.info(f"Export generated: {filename} ({file_size} bytes) in {duration_ms}ms")`
  - [ ] Log comparison results: original vs edited segment counts
  - [ ] Test: Verify logs appear in console during export

- [ ] Task 6: Add privacy notice to frontend UI (AC: #8)
  - [ ] Update `frontend/src/components/ExportButton.vue` (if exists) or ResultsView
  - [ ] Add text notice: "Note: Edited transcriptions may be retained to improve our AI model."
  - [ ] Position near export button or in export modal
  - [ ] Styling: Subtle, informative (not alarming)
  - [ ] Test: Verify notice visible before export action

- [ ] Task 7: Write backend unit tests for export service (AC: all)
  - [ ] Create `backend/tests/test_services_export.py`
  - [ ] Test: `test_generate_srt()` - verify SRT format, timestamp conversion
  - [ ] Test: `test_generate_txt()` - verify plain text, no timestamps
  - [ ] Test: `test_save_edited_transcription()` - verify files created, metadata correct
  - [ ] Test: `test_changes_detection()` - verify accurate diff counting
  - [ ] Create `backend/tests/test_api_export.py`
  - [ ] Test: `test_export_srt_format()` - POST with SRT, verify response
  - [ ] Test: `test_export_txt_format()` - POST with TXT, verify response
  - [ ] Test: `test_export_job_not_found()` - 404 error handling
  - [ ] Test: `test_export_invalid_format()` - 400 error handling
  - [ ] Test: `test_export_empty_segments()` - 400 error handling
  - [ ] Run: `cd backend && source .venv/Scripts/activate && pytest tests/test_api_export.py tests/test_services_export.py -v`

- [ ] Task 8: Manual validation and integration testing (AC: all)
  - [ ] Start backend: Verify server runs without errors
  - [ ] Navigate to FastAPI auto-docs: `http://localhost:8000/docs`
  - [ ] Verify POST /export/{job_id} endpoint documented with request/response schemas
  - [ ] Use Swagger UI to test SRT export with sample segments
  - [ ] Verify file downloads with correct filename format
  - [ ] Use Swagger UI to test TXT export
  - [ ] Check `/uploads/{job_id}/` directory for edited.json and export_metadata.json
  - [ ] Verify metadata fields are populated correctly
  - [ ] Test error scenarios: invalid job_id, wrong format, empty segments array
  - [ ] Verify privacy notice visible in frontend (if Task 6 completed)</tasks>
  </story>

  <acceptanceCriteria>1. POST /export/{job_id} endpoint accepts edited subtitle array in request body
2. Generates SRT file format from edited subtitles
3. Generates TXT file format (plain text, no timestamps) from edited subtitles
4. Stores both original transcription and edited version on server with job_id reference
5. Stores metadata: edit timestamp, number of changes, export format requested
6. Returns exported files for download (multipart response or separate endpoints)
7. API endpoint documented in FastAPI auto-docs
8. Privacy notice: Inform users that edited transcriptions may be retained for model improvement</acceptanceCriteria>

  <artifacts>
    <docs>
      <doc path="docs/PRD.md" title="Product Requirements Document" section="Functional Requirements - Export & Data Persistence">
FR014: System shall export edited transcriptions in SRT (SubRip) subtitle format
FR015: System shall export edited transcriptions in plain TXT format for LLM processing
FR016: System shall capture both original AI-generated and human-edited versions during export
FR019: System shall store human-edited transcription versions to enable data flywheel analysis
      </doc>
      <doc path="docs/tech-spec-epic-2.md" title="Epic 2 Technical Specification" section="Data Models and Contracts - ExportRequest & ExportMetadata">
Defines Pydantic models: ExportRequest (segments array + format Literal['srt', 'txt']) and ExportMetadata (job_id, original_segment_count, edited_segment_count, export_timestamp, format_requested, changes_detected). Storage structure: /uploads/{job_id}/edited.json and export_metadata.json for data flywheel capture.
      </doc>
      <doc path="docs/tech-spec-epic-2.md" title="Epic 2 Technical Specification" section="APIs and Interfaces - POST /export/{job_id}">
Endpoint accepts ExportRequest body, validates job_id exists, generates SRT or TXT file, stores edited version to data flywheel (edited.json + export_metadata.json), returns file download with Content-Disposition header. Content-Type: application/x-subrip (SRT) or text/plain (TXT).
      </doc>
      <doc path="docs/tech-spec-epic-2.md" title="Epic 2 Technical Specification" section="SRT and TXT Format Specifications">
SRT format: Sequence number, HH:MM:SS,mmm timestamps, subtitle text, blank line separator. TXT format: Space-separated plain text with no timestamps. SRT timestamp conversion: float seconds to HH:MM:SS,mmm (e.g., 0.5 → 00:00:00,500).
      </doc>
      <doc path="docs/architecture.md" title="Decision Architecture" section="Export File Naming Convention">
Format: transcript-{job_id}.{ext}. Rationale: Prefix identifies file type clearly, job ID ensures uniqueness, file extension indicates format, browser downloads use this name by default. Affects: Epic 2.5, 2.6 (export API, frontend download).
      </doc>
      <doc path="docs/architecture.md" title="Decision Architecture" section="Media File Storage Strategy - Data Flywheel">
Structure: /uploads/{job_id}/ contains original.{ext}, transcription.json, edited.json (human-edited version). Separate JSON files enable data flywheel (FR019: persist original + edited). Simple filesystem approach (no S3/CDN needed for MVP).
      </doc>
    </docs>
    <code>
      <file path="backend/app/models.py" relevance="high">
        <symbol name="TranscriptionSegment" kind="class" lines="70-98">
          Existing Pydantic model with start (float), end (float), text (str) fields.
          Story 2.5 adds ExportRequest and ExportMetadata models to this file.
        </symbol>
        <note>Models already include UploadResponse, StatusResponse, TranscriptionResult from Epic 1</note>
      </file>
      <file path="backend/app/main.py" relevance="high">
        <symbol name="serve_media" kind="function" lines="301-393">
          Example endpoint pattern for FileResponse with HTTP Range support.
          Shows UUID validation, job directory lookup, error handling (HTTPException 400/404).
          Story 2.5 follows similar pattern for POST /export/{job_id} endpoint.
        </symbol>
        <note>Existing endpoints: root(), upload_file(), get_status(), get_result(), serve_media()</note>
      </file>
      <file path="backend/app/services/file_handler.py" relevance="medium">
        <symbol name="FileHandler" kind="class" lines="14-146">
          File storage utility class with EXTENSION_MIME_MAP, save_upload(), generate_job_id() methods.
          Story 2.5 uses similar pattern: job_id subdirectories under /uploads/{job_id}/
        </symbol>
        <note>File storage convention: /uploads/{job_id}/original.{ext}, transcription.json (Epic 1)</note>
      </file>
      <file path="backend/app/config.py" relevance="medium">
        <symbol name="Settings" kind="class">
          UPLOAD_DIR = "/uploads" (line 24) - Base directory for all file operations.
          Story 2.5 writes edited.json and export_metadata.json to /uploads/{job_id}/
        </symbol>
      </file>
      <file path="backend/tests/conftest.py" relevance="high">
        <symbol name="test_client" kind="fixture" lines="13-24">
          FastAPI TestClient fixture for API endpoint testing.
        </symbol>
        <symbol name="temp_upload_dir" kind="fixture">
          Temporary directory fixture for file operations (implied from test_api_media.py usage).
        </symbol>
        <note>Test pattern: monkeypatch settings.UPLOAD_DIR to temp directory for isolation</note>
      </file>
      <file path="backend/tests/test_api_media.py" relevance="high">
        <note>Reference test file showing:
          - Class-based test organization (TestServeMediaSuccess, TestServeMediaNotFound)
          - temp_upload_dir + monkeypatch pattern for file operations
          - job_id as valid UUID string (550e8400-e29b-41d4-a716-446655440001)
          - Assert on response.status_code, headers, content
          Story 2.5 creates test_api_export.py and test_services_export.py following this pattern.
        </note>
      </file>
    </code>
    <dependencies>
      <backend manifest="backend/requirements.txt">
        <existing>
          - fastapi==0.120.0 (REST API framework)
          - pydantic==2.10.3 (data validation, BaseModel)
          - pydantic-settings==2.7.0 (Settings configuration)
          - pytest==7.4.4 (testing framework)
          - pytest-mock==3.12.0 (mocking library)
          - pytest-cov==4.1.0 (coverage reporting)
          - httpx==0.28.1 (TestClient for FastAPI)
          - fakeredis==2.21.1 (in-memory Redis for tests)
        </existing>
        <new>
          None required - Story 2.5 uses Python built-ins (json, os, datetime, pathlib).
          Note: Tech spec initially mentioned python-magic and aiofiles, but these are NOT needed:
          - FileResponse handles HTTP Range automatically (no aiofiles needed)
          - FileHandler.EXTENSION_MIME_MAP already exists (no python-magic needed)
        </new>
      </backend>
      <frontend manifest="frontend/package.json">
        <note>Story 2.5 is backend-focused. Frontend changes limited to privacy notice in Task 6.</note>
      </frontend>
    </dependencies>
  </artifacts>

  <constraints>
- CRITICAL: Backend Python environment isolation - ALWAYS activate uv virtual environment before running Python commands (cd backend && source .venv/Scripts/activate)
- Verify Python 3.12.x from .venv: which python should show backend/.venv/Scripts/python
- Use uv pip install for new dependencies (NOT global pip)
- All backend functions must have type hints (Python) and explicit types (TypeScript)
- Error handling: Use HTTPException (400, 404, 500) with human-readable detail messages
- Logging: Use Python logging module (INFO for operations, ERROR for failures)
- Date/time: ISO 8601 UTC strings (datetime.now(timezone.utc).isoformat())
- Testing: pytest + pytest-mock for backend, 70%+ coverage target
- No new external dependencies expected (use Python built-ins: json, os, datetime)
  </constraints>
  <interfaces>
    <interface name="POST /export/{job_id}" kind="REST endpoint" path="backend/app/main.py">
Request: ExportRequest JSON body { segments: list[TranscriptionSegment], format: Literal['srt', 'txt'] }
Response: File download with Content-Disposition header, Content-Type: application/x-subrip (SRT) or text/plain (TXT)
Filename: transcript-{job_id}.{ext}
    </interface>
    <interface name="TranscriptionSegment" kind="Pydantic Model" path="backend/app/models.py">
class TranscriptionSegment(BaseModel):
    start: float  # Float seconds
    end: float    # Float seconds
    text: str
    </interface>
    <interface name="ExportRequest" kind="Pydantic Model (NEW)" path="backend/app/models.py">
class ExportRequest(BaseModel):
    segments: list[TranscriptionSegment]
    format: Literal['srt', 'txt']
    </interface>
    <interface name="ExportMetadata" kind="Pydantic Model (NEW)" path="backend/app/models.py">
class ExportMetadata(BaseModel):
    job_id: str
    original_segment_count: int
    edited_segment_count: int
    export_timestamp: str  # ISO 8601 UTC
    format_requested: str  # 'srt' or 'txt'
    changes_detected: int  # Number of segments with text differences
    </interface>
    <interface name="generate_srt" kind="function signature (NEW)" path="backend/app/services/export_service.py">
def generate_srt(segments: List[TranscriptionSegment]) -> str:
    """Generate SRT subtitle format from segments"""
    </interface>
    <interface name="generate_txt" kind="function signature (NEW)" path="backend/app/services/export_service.py">
def generate_txt(segments: List[TranscriptionSegment]) -> str:
    """Generate plain text format (no timestamps)"""
    </interface>
    <interface name="save_edited_transcription" kind="function signature (NEW)" path="backend/app/services/export_service.py">
def save_edited_transcription(job_id: str, segments: List[TranscriptionSegment], format_requested: str) -> ExportMetadata:
    """Save edited transcription and metadata for data flywheel"""
    </interface>
  </interfaces>
  <tests>
    <standards>
      Framework: pytest + pytest-mock + pytest-cov (already configured from Epic 1)
      Coverage Target: 70%+ for backend code (maintain Epic 1 standard)
      Test Organization: Class-based grouping (e.g., TestExportSRTFormat, TestExportErrors)
      Fixtures: test_client (FastAPI), temp_upload_dir + monkeypatch for file isolation
      Assertions: response.status_code, headers (Content-Type, Content-Disposition), response content/JSON
      Mock Strategy: monkeypatch settings.UPLOAD_DIR to temp directories, avoid real file I/O outside temp
      Run Command: cd backend && source .venv/Scripts/activate && pytest tests/test_api_export.py tests/test_services_export.py -v --cov=app
    </standards>
    <locations>
      backend/tests/test_services_export.py (NEW) - Unit tests for export service functions:
        - test_format_srt_timestamp() - verify HH:MM:SS,mmm conversion
        - test_generate_srt() - verify SRT format structure
        - test_generate_txt() - verify plain text output
        - test_save_edited_transcription() - verify data flywheel files created
        - test_changes_detection() - verify diff counting accuracy

      backend/tests/test_api_export.py (NEW) - Integration tests for POST /export endpoint:
        - TestExportSuccess class:
          - test_export_srt_format() - POST with SRT, verify response
          - test_export_txt_format() - POST with TXT, verify response
        - TestExportErrors class:
          - test_export_job_not_found() - 404 error handling
          - test_export_invalid_format() - 422 Pydantic validation error
          - test_export_empty_segments() - 400 error handling

      backend/tests/conftest.py (MODIFY) - Add fixture for mock job with transcription.json:
        - mock_job_with_transcription fixture creates temp job directory with original transcription
    </locations>
    <ideas>
      1. Edge Case: Test timestamp conversion for 0.0 seconds (00:00:00,000) and >1 hour (01:15:30,500)
      2. Edge Case: Test SRT generation with 1000+ segments (performance validation)
      3. Edge Case: Test changes_detected = 0 when user exports without editing
      4. Edge Case: Test changes_detected with partial edits (3 out of 10 segments changed)
      5. Data Integrity: Verify edited.json and export_metadata.json are valid JSON after save
      6. Data Integrity: Verify metadata.changes_detected matches actual text differences
      7. Error Handling: Test corrupted transcription.json (invalid JSON) returns 500
      8. Error Handling: Test missing /uploads/{job_id}/ directory returns 404
      9. Content-Type Headers: Verify application/x-subrip for SRT, text/plain for TXT
      10. Content-Disposition: Verify filename format transcript-{job_id}.srt matches spec
      11. Concurrency: Test multiple exports of same job_id (last-write-wins acceptable)
      12. Manual Validation: Use Swagger UI (/docs) to test export with real transcription from Epic 1
    </ideas>
  </tests>
</story-context>
