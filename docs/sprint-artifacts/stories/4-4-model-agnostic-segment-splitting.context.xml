<story-context id=".bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>4</epicId>
    <storyId>4.4</storyId>
    <title>Model-Agnostic Segment Splitting Component</title>
    <status>ready-for-dev</status>
    <generatedAt>2025-11-17</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>E:\Projects\KlipNote\docs\sprint-artifacts\4-4-model-agnostic-segment-splitting.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>user editing Chinese subtitles</asA>
    <iWant>long segments automatically split with preserved timing metadata</iWant>
    <soThat>each subtitle is readable, conforms to industry conventions, and maintains precise character/word timing</soThat>
    <tasks>
      - Task 1: Create SegmentSplitter base interface (AC: 1)
        - Subtask 1.1: Define abstract `BaseSegmentSplitter` or extend `EnhancementComponent` pattern
        - Subtask 1.2: Define `split()` method signature accepting List[EnhancedSegment]
        - Subtask 1.3: Define `get_metrics()` method for processing statistics
      - Task 2: Implement Chinese text length estimation (AC: 3)
        - Subtask 2.1: Implement character counting for Chinese text (detect CJK characters)
        - Subtask 2.2: Apply 0.4s per character heuristic for duration estimation
        - Subtask 2.3: Add configurable max_chars parameter (default: 200)
      - Task 3: Implement natural boundary detection (AC: 2)
        - Subtask 3.1: Detect punctuation marks (。！？，；) for Chinese text
        - Subtask 3.2: Use energy-based pause detection as fallback (integrate with refiner's approach)
        - Subtask 3.3: Split segments >7s at optimal boundaries
      - Task 4: Implement char/word timing preservation (AC: 5)
        - Subtask 4.1: When splitting segment, distribute char timing arrays across split segments
        - Subtask 4.2: When splitting segment, distribute word timing arrays across split segments
        - Subtask 4.3: Validate timing arrays remain sequential and within segment bounds after split
      - Task 5: Implement segment merging logic (AC: 4)
        - Subtask 5.1: Detect short segments <1s
        - Subtask 5.2: Merge with adjacent segment if combined duration <7s and chars <200
        - Subtask 5.3: Merge char/word timing arrays when merging segments
      - Task 6: Implement metadata tracking (AC: 6)
        - Subtask 6.1: Append "segment_split" to enhancements_applied list
        - Subtask 6.2: Record processing metrics (segments before/after, split count, merge count)
      - Task 7: Optimize performance (AC: 8)
        - Subtask 7.1: Profile processing time on 500-segment test dataset
        - Subtask 7.2: Optimize splitting algorithm (avoid unnecessary iterations)
        - Subtask 7.3: Verify <3 min processing time constraint
      - Task 8: Write unit tests (AC: 9)
        - Subtask 8.1: Test long segment splitting (>7s)
        - Subtask 8.2: Test short segment merging (<1s)
        - Subtask 8.3: Test char/word timing preservation after split/merge
        - Subtask 8.4: Test Chinese character count estimation
        - Subtask 8.5: Test edge cases (empty segments, very long text, no punctuation)
      - Task 9: Write integration tests (AC: 10)
        - Subtask 9.1: Test with real Chinese audio (verify 95% compliance)
        - Subtask 9.2: Test with real English audio (verify timing array integrity)
        - Subtask 9.3: Test end-to-end pipeline: BELLE-2 → Refiner → Splitter
        - Subtask 9.4: Validate constraint compliance metrics (<200 chars, 1-7s duration)
    </tasks>
  </story>

  <acceptanceCriteria>
    AC-4.4-1: SegmentSplitter component works with any model's segment output
    - `app/ai_services/enhancement/splitter.py` implements `EnhancementComponent` interface
    - No model-specific dependencies

    AC-4.4-2: Segments >7 seconds split at natural boundaries (punctuation, pauses)
    - Constructor accepts `max_duration` parameter (default: 7.0)
    - Splitting algorithm prefers punctuation marks (。！？，；) as split points
    - Falls back to pause detection if no punctuation available

    AC-4.4-3: Chinese text length estimation implemented (character count × 0.4s)
    - Heuristic: ~150-180 chars/minute speaking rate for Mandarin = ~2.5-3 chars/second
    - Conservative estimate: 0.4s per character ensures readability
    - Constructor accepts `max_chars` parameter (default: 200)

    AC-4.4-4: Short segments <1s merged when safe
    - Merging logic checks: adjacent segment timestamps, text length constraints
    - Only merges if combined duration <7s and combined chars <200
    - Preserves segment boundaries if merging would violate constraints

    AC-4.4-5: 95% of output segments meet 1-7s, <200 char constraints
    - Validation script calculates compliance percentage
    - Test fails if compliance <95%
    - Logs statistics: mean duration, P95 duration, mean chars, P95 chars

    AC-4.4-6: Processing completes in <3 minutes for 500 segments
    - Performance benchmark on 500-segment test case

    AC-4.4-7: Works with both BELLE-2 and WhisperX segment formats
    - Integration tests on both models' outputs

    AC-4.4-8: Component can be enabled/disabled via configuration
    - `EnhancementConfig.split_enabled` boolean flag
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/architecture.md</path>
        <title>Decision Architecture - KlipNote</title>
        <section>Enhanced Data Schema Architecture (Epic 4)</section>
        <snippet>Hierarchical metadata schema supporting rich transcription metadata, processing pipeline tracking, and multi-language optimization. Module: backend/app/ai_services/schema.py defines EnhancedSegment with CharTiming and WordTiming arrays critical for Chinese subtitle editing.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Decision Architecture - KlipNote</title>
        <section>AI Service Abstraction Strategy</section>
        <snippet>Model-agnostic enhancement component architecture with pluggable optimization pipeline. Components append to enhancements_applied list (enables pipeline transparency). Graceful degradation: Component failures should not break pipeline.</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>KlipNote - Epic Breakdown</title>
        <section>Epic 4: Multi-Model Transcription Framework & Composable Enhancements</section>
        <snippet>Story 4.4 implements segment splitting as composable enhancement component running after TimestampRefiner in pipeline chain. Must preserve EnhancedSegment structure with rich metadata from previous components.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-4.md</path>
        <title>Epic Technical Specification: Multi-Model Framework</title>
        <section>Enhancement Component Architecture</section>
        <snippet>Enhancement components implement EnhancementComponent interface with process() and get_metrics() methods. Components work with any transcription model output (BELLE-2, WhisperX). Pipeline configuration via comma-separated component names (vad,refine,split).</snippet>
      </doc>
    </docs>

    <code>
      <artifact>
        <path>backend/app/ai_services/enhancement/base_refiner.py</path>
        <kind>abstract base</kind>
        <symbol>BaseRefiner</symbol>
        <lines>14-48</lines>
        <reason>Abstract interface pattern for refinement components - provides is_available(), refine(), get_metrics() contract that SegmentSplitter should follow or adapt</reason>
      </artifact>
      <artifact>
        <path>backend/app/ai_services/schema.py</path>
        <kind>schema</kind>
        <symbol>EnhancedSegment, CharTiming, WordTiming</symbol>
        <lines>19-58</lines>
        <reason>Core schema definitions for enhanced segment structure including char/word timing arrays that must be preserved when splitting segments</reason>
      </artifact>
      <artifact>
        <path>backend/app/ai_services/enhancement/timestamp_refiner.py</path>
        <kind>component</kind>
        <symbol>TimestampRefiner</symbol>
        <lines>30-150</lines>
        <reason>Story 4.3 reference implementation showing component structure, metrics tracking, timing array population, and enhancements_applied metadata pattern to replicate</reason>
      </artifact>
      <artifact>
        <path>backend/app/ai_services/enhancement/vad_manager.py</path>
        <kind>component</kind>
        <symbol>VADManager</symbol>
        <lines>*</lines>
        <reason>Story 4.2 VAD component demonstrates multi-engine pattern and metadata tracking - similar pattern for segment splitting with punctuation vs pause detection fallback</reason>
      </artifact>
    </code>

    <dependencies>
      <python>
        - Standard Library: re (for CJK character detection, punctuation matching)
        - Standard Library: time (for performance metrics)
        - Standard Library: logging (for component logging)
        - Optional: librosa (for energy-based pause detection fallback - already installed from Story 4.3)
        - Optional: numpy (for audio analysis - already installed from Story 4.3)
      </python>
    </dependencies>
  </artifacts>

  <interfaces>
    <interface>
      <name>EnhancementComponent Interface</name>
      <kind>abstract base</kind>
      <signature>
        class SegmentSplitter:
            def __init__(self, max_duration: float = 7.0, max_chars: int = 200) -> None
            @classmethod
            def is_available(cls) -> bool
            def process(self, segments: List[EnhancedSegment], **kwargs) -> List[EnhancedSegment]
            def get_metrics(self) -> Dict[str, Any]
      </signature>
      <path>backend/app/ai_services/enhancement/base_refiner.py</path>
      <note>Pattern established by BaseRefiner - SegmentSplitter can extend or follow similar interface</note>
    </interface>
    <interface>
      <name>EnhancedSegment Schema</name>
      <kind>TypedDict</kind>
      <signature>
        class EnhancedSegment(BaseSegment, total=False):
            start: float  # Required
            end: float    # Required
            text: str     # Required
            words: List[WordTiming]
            chars: List[CharTiming]
            enhancements_applied: List[str]
            source_model: Optional[str]
            # ... additional metadata fields
      </signature>
      <path>backend/app/ai_services/schema.py</path>
      <note>Segments must preserve this structure when splitting - distribute char/word arrays across new segments</note>
    </interface>
    <interface>
      <name>CharTiming and WordTiming Arrays</name>
      <kind>TypedDict</kind>
      <signature>
        class CharTiming:
            char: str
            start: float
            end: float
            score: NotRequired[float]

        class WordTiming:
            word: str
            start: float
            end: float
            score: NotRequired[float]
            language: NotRequired[str]
      </signature>
      <path>backend/app/ai_services/schema.py</path>
      <note>CRITICAL: Must be preserved and correctly distributed when splitting segments - validates timing integrity</note>
    </interface>
  </interfaces>

  <constraints>
    <constraint>Model-Agnostic Design: Must work with both BELLE-2 and WhisperX segment outputs without model-specific logic</constraint>
    <constraint>Performance: Processing <3 min for 500 segments (faster than TimestampRefiner's 5 min) - no audio file access required</constraint>
    <constraint>Subtitle Industry Standards: 95% compliance with 1-7s duration and ≤200 character constraints per segment</constraint>
    <constraint>Timing Array Integrity: Char/word timing arrays must remain sequential with no gaps/overlaps after splitting/merging</constraint>
    <constraint>Component Integration: Typically runs after TimestampRefiner in pipeline chain - must accept and preserve existing enhancements_applied metadata</constraint>
    <constraint>Configuration Pattern: Add settings to backend/app/config.py following existing SEGMENT_SPLITTER_* naming convention</constraint>
    <constraint>Magic Numbers: Extract all constants (7.0s, 200 chars, 0.4s/char) to class-level or config constants</constraint>
    <constraint>Single-Pass Algorithm: Process segments sequentially to meet performance target - avoid multiple iterations</constraint>
    <constraint>Graceful Degradation: Component failures should not break pipeline - return original segments with error logging if split logic fails</constraint>
    <constraint>Path Validation: No file access required for SegmentSplitter (text-only processing) unlike VAD/Refiner components</constraint>
  </constraints>

  <tests>
    <standards>
      Testing standards follow pytest patterns established in Epic 1-3. Unit tests mock external dependencies and validate logic with synthetic data. Integration tests use real audio files to validate end-to-end behavior. Test files located in backend/tests/ with test_segment_splitter.py for unit tests and test_segment_splitter_integration.py for integration tests. Use pytest-mock for mocking, pytest-cov for coverage reporting. Target: 80%+ coverage for new component code.
    </standards>

    <locations>
      - backend/tests/test_segment_splitter.py (unit tests)
      - backend/tests/test_segment_splitter_integration.py (integration tests)
      - Test fixtures in backend/tests/fixtures/ (reuse existing audio files from Story 4.3 tests)
    </locations>

    <ideas>
      <idea acceptanceCriteria="AC-4.4-1, AC-4.4-2">
        Test: test_split_long_segment_at_punctuation()
        - Create EnhancedSegment with 10s duration and Chinese text containing punctuation marks (。)
        - Verify segment splits into 2+ segments at punctuation boundaries
        - Validate split segments meet duration constraints (<7s each)
        - Ensure "segment_split" appended to enhancements_applied
      </idea>
      <idea acceptanceCriteria="AC-4.4-3">
        Test: test_chinese_character_length_constraint()
        - Create segment with 250 Chinese characters (exceeds 200 char limit)
        - Verify segment splits even without punctuation
        - Validate all output segments ≤200 characters
        - Test character counting accurately detects CJK characters
      </idea>
      <idea acceptanceCriteria="AC-4.4-4">
        Test: test_merge_short_segments()
        - Create two adjacent segments: 0.8s and 0.9s duration (both <1s)
        - Verify segments merge into single segment
        - Validate merged segment duration = 1.7s, text concatenated
        - Ensure char/word timing arrays correctly merged
      </idea>
      <idea acceptanceCriteria="AC-4.4-5">
        Test: test_constraint_compliance_on_real_data()
        - Process real Chinese transcription with 500+ segments
        - Calculate compliance percentage: (compliant_segments / total) ≥ 0.95
        - Validate duration (1-7s) and character (≤200) constraints
        - Log P95 statistics for duration and character count
      </idea>
      <idea acceptanceCriteria="AC-4.4-6">
        Test: test_performance_500_segments()
        - Create synthetic dataset with 500 segments
        - Measure processing time with time.perf_counter()
        - Assert total_time < 180 seconds (3 minutes)
        - Verify no unnecessary file I/O (text-only processing)
      </idea>
      <idea acceptanceCriteria="AC-4.4-7">
        Test: test_timing_arrays_preserved_after_split()
        - Create segment with chars array and words array from Story 4.3 output
        - Split segment at boundary (e.g., 5.0s mark)
        - Verify chars[:N] go to first segment, chars[N:] to second
        - Validate timing arrays sequential (no gaps, first.end ≤ second.start)
        - Ensure all char/word timestamps within their segment bounds
      </idea>
      <idea acceptanceCriteria="AC-4.4-8">
        Integration Test: test_belle2_refiner_splitter_pipeline()
        - Transcribe Chinese audio with BELLE-2
        - Apply TimestampRefiner (Story 4.3)
        - Apply SegmentSplitter (this story)
        - Validate enhancements_applied = ["timestamp_refine", "segment_split"]
        - Verify char/word timing integrity through full pipeline
      </idea>
      <idea acceptanceCriteria="AC-4.4-1">
        Edge Case Test: test_empty_segments_list()
        - Pass empty list to splitter.process([])
        - Verify returns empty list without errors
        - Ensure metrics report 0 segments processed
      </idea>
      <idea acceptanceCriteria="AC-4.4-2">
        Edge Case Test: test_no_punctuation_fallback_to_pause()
        - Create long segment (>7s) with Chinese text but NO punctuation
        - Mock energy-based pause detection (librosa)
        - Verify segment splits at low-energy pause points
        - Validate fallback mechanism logs appropriate warning
      </idea>
    </ideas>
  </tests>
</story-context>
